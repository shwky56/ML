{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a dataset and  preview images\n",
    "\n",
    "A model is only as good as its dataset.\n",
    "\n",
    "Training tools need lots of high-quality data to build accurate models. We'll use the [STL-10 dataset](https://cs.stanford.edu/~acoates/stl10/) of 10,000 photos to build our image classifier. Get started by downloading the dataset with puthon code and previewing a handful of images from it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:  \n",
    "##### import librarys and define constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import urllib.request as urllib\n",
    "import tarfile\n",
    "# path to the directory with the data\n",
    "DATA_DIR = \"../stl10_dataset/\"\n",
    "\n",
    "# url of the binary data\n",
    "DATA_URL = \"http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2:\n",
    "##### download dataset and save in `stl10_dataset` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def download_dataset_and_extract():\n",
    "    # Download the STL-10 dataset using https request\n",
    "\n",
    "    dest_directory = DATA_DIR\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split(\"/\")[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write(\n",
    "                \"\\rDownloading %s %.2f%%\"\n",
    "                % (filename, float(count * block_size) / float(total_size) * 100.0)\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        filepath, _ = urllib.urlretrieve(DATA_URL, filepath, reporthook=_progress)\n",
    "        print(\"Downloaded\", filename)\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dataset_and_extract()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3:\n",
    "##### extract dataset file to binry files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataste():\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
